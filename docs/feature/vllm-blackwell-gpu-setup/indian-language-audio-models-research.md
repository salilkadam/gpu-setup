# Indian Language Audio Models Research

## ğŸ¯ **Objective**
Research and implement the best STT (Speech-to-Text) and TTS (Text-to-Speech) models for Indian languages that are compatible with our vLLM-based inference system.

## ğŸ“Š **Research Findings**

### **ğŸ” STT (Speech-to-Text) Models**

#### **1. OpenAI Whisper Large v3** â­ **RECOMMENDED**
- **Model**: `openai/whisper-large-v3`
- **Size**: ~3GB
- **Languages**: 99 languages including Hindi, Tamil, Telugu, Bengali, Gujarati, Marathi, Punjabi, Urdu
- **Architecture**: `WhisperForConditionalGeneration`
- **vLLM Compatibility**: âŒ **NOT COMPATIBLE** (vLLM doesn't support WhisperForConditionalGeneration)
- **Alternative**: Use with Transformers backend or separate service

#### **2. Whisper Large v3 Turbo** â­ **ALTERNATIVE**
- **Model**: `openai/whisper-large-v3-turbo`
- **Size**: ~3GB
- **Languages**: Same as v3 but optimized for speed
- **Architecture**: `WhisperForConditionalGeneration`
- **vLLM Compatibility**: âŒ **NOT COMPATIBLE**

### **ğŸ”Š TTS (Text-to-Speech) Models**

#### **1. SYSPIN Coqui TTS Models** â­ **RECOMMENDED**
- **Hindi Female**: `SYSPIN/tts_vits_coquiai_HindiFemale`
- **Hindi Male**: `SYSPIN/tts_vits_coquiai_HindiMale`
- **Bengali Female**: `SYSPIN/tts_vits_coquiai_BengaliFemale`
- **Bengali Male**: `SYSPIN/tts_vits_coquiai_BengaliMale`
- **Chhattisgarhi Female**: `SYSPIN/tts_vits_coquiai_ChhattisgarhiFemale`
- **Chhattisgarhi Male**: `SYSPIN/tts_vits_coquiai_ChhattisgarhiMale`
- **Architecture**: VITS (Variational Inference with adversarial learning for end-to-end Text-to-Speech)
- **vLLM Compatibility**: âŒ **NOT COMPATIBLE** (TTS models not supported by vLLM)

#### **2. Other TTS Options**
- **Coqui TTS**: General-purpose TTS framework
- **Festival**: Traditional TTS system
- **eSpeak**: Open-source speech synthesizer

## ğŸš§ **Critical Challenge: vLLM Compatibility**

### **âŒ Problem**
**vLLM does NOT support audio models!**

- **WhisperForConditionalGeneration**: Not supported by vLLM
- **TTS Models**: Not supported by vLLM
- **Audio Processing**: vLLM is designed for text-only LLM inference

### **âœ… Solution Strategy**

#### **Option 1: Hybrid Architecture** â­ **RECOMMENDED**
- **vLLM**: Handle text-only use cases (Agent, Avatar, Multimodal, Video)
- **Separate Audio Services**: Handle STT and TTS
- **API Gateway**: Route requests to appropriate services

#### **Option 2: Transformers Backend**
- Use Hugging Face Transformers for audio models
- Integrate with our existing routing system
- Lower performance but full compatibility

## ğŸ—ï¸ **Implementation Plan**

### **Phase 1: Audio Service Setup**
1. **STT Service**: Deploy Whisper Large v3 with Transformers
2. **TTS Service**: Deploy Coqui TTS models
3. **API Integration**: Add audio endpoints to routing system

### **Phase 2: Model Selection**
1. **STT**: `openai/whisper-large-v3` (3GB)
2. **TTS Hindi**: `SYSPIN/tts_vits_coquiai_HindiFemale` + `SYSPIN/tts_vits_coquiai_HindiMale`
3. **TTS Bengali**: `SYSPIN/tts_vits_coquiai_BengaliFemale` + `SYSPIN/tts_vits_coquiai_BengaliMale`

### **Phase 3: Integration**
1. **Docker Services**: Separate containers for audio processing
2. **API Gateway**: Route audio requests to appropriate services
3. **Monitoring**: Add audio service monitoring

## ğŸ“‹ **Indian Languages Coverage**

### **STT Support (Whisper Large v3)**
- âœ… **Hindi** (hi)
- âœ… **Tamil** (ta)
- âœ… **Telugu** (te)
- âœ… **Bengali** (bn)
- âœ… **Gujarati** (gu)
- âœ… **Marathi** (mr)
- âœ… **Punjabi** (pa)
- âœ… **Urdu** (ur)
- âœ… **Kannada** (kn)
- âœ… **Malayalam** (ml)
- âœ… **Odia** (or)
- âœ… **Assamese** (as)

### **TTS Support (SYSPIN Models)**
- âœ… **Hindi** (Male + Female voices)
- âœ… **Bengali** (Male + Female voices)
- âœ… **Chhattisgarhi** (Male + Female voices)

## ğŸ¯ **Recommended Implementation**

### **Architecture**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Gateway   â”‚    â”‚   vLLM Service  â”‚    â”‚  Audio Services â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  Route Requests â”‚â”€â”€â”€â–¶â”‚  Text Models    â”‚    â”‚  STT + TTS      â”‚
â”‚                 â”‚    â”‚  (MiniCPM-V-4)  â”‚    â”‚  (Whisper+TTS)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Services**
1. **vLLM Service**: MiniCPM-V-4 (Agent, Avatar, Multimodal, Video)
2. **STT Service**: Whisper Large v3 (Speech-to-Text)
3. **TTS Service**: Coqui TTS models (Text-to-Speech)

### **Use Case Coverage**
- **Agent**: âœ… vLLM (MiniCPM-V-4)
- **Avatar**: âœ… vLLM (MiniCPM-V-4)
- **STT**: âœ… Audio Service (Whisper)
- **TTS**: âœ… Audio Service (Coqui TTS)
- **Multimodal**: âœ… vLLM (MiniCPM-V-4)
- **Video**: âœ… vLLM (MiniCPM-V-4)

**Total Coverage: 6/6 (100%)**

## ğŸš€ **Next Steps**
1. Download and test Whisper Large v3
2. Download and test Coqui TTS models
3. Create separate Docker services for audio processing
4. Integrate with existing routing system
5. Test end-to-end audio functionality
